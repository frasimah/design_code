"""
Robust —Å–∫—Ä–∞–ø–µ—Ä: –ø–æ–ª–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ DOM + –ø—Ä–æ–∫—Ä—É—Ç–∫—É –∫–∞—Ä—É—Å–µ–ª–∏ + Gemini –≤–∞–ª–∏–¥–∞—Ü–∏—é
"""

import asyncio
from pathlib import Path
from typing import Optional, List, Dict, Any
from datetime import datetime
from playwright.async_api import async_playwright, Page, Browser
from rich.console import Console
import re

import sys
sys.path.insert(0, str(__file__).rsplit("/", 3)[0])

from config.settings import VandersandenConfig, GEMINI_API_KEY, DATA_DIR
from src.scraper.gemini_analyzer import GeminiVisionAnalyzer
from src.scraper.utils import clean_text, extract_article, extract_weight, extract_number


console = Console()

SCREENSHOTS_DIR = DATA_DIR / "screenshots"
SCREENSHOTS_DIR.mkdir(parents=True, exist_ok=True)

DOWNLOADS_DIR = DATA_DIR / "downloads"
DOWNLOADS_DIR.mkdir(parents=True, exist_ok=True)


class RobustProductScraper:
    """
    Robust —Å–∫—Ä–∞–ø–µ—Ä –ø—Ä–æ–¥—É–∫—Ç–æ–≤ Vandersanden:
    - –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –∫–∞—Ä—É—Å–µ–ª–∏ –¥–ª—è –ø–æ–∫–∞–∑–∞ –≤—Å–µ—Ö –∫–∞—Ä—Ç–æ—á–µ–∫
    - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ DOM –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ
    - –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    - Gemini –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """
    
    def __init__(self, api_key: str = None, headless: bool = True, use_gemini: bool = True):
        self.api_key = api_key or GEMINI_API_KEY
        self.headless = headless
        self.use_gemini = use_gemini and bool(self.api_key)
        self.browser: Optional[Browser] = None
        self.gemini: Optional[GeminiVisionAnalyzer] = None
        self.base_url = VandersandenConfig.BASE_URL
    
    async def __aenter__(self):
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(headless=self.headless)
        if self.use_gemini:
            self.gemini = GeminiVisionAnalyzer(self.api_key)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.browser:
            await self.browser.close()
        await self.playwright.stop()
        if self.gemini:
            self.gemini.close()
    
    async def scrape_product(self, url: str) -> dict:
        """–ü–æ–ª–Ω—ã–π —Å–∫—Ä–∞–ø–ø–∏–Ω–≥ –ø—Ä–æ–¥—É–∫—Ç–∞ —Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π 100% –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        
        console.log(f"[bold blue]üß± Robust scraping:[/bold blue] {url}")
        
        page = await self.browser.new_page(viewport={"width": 1920, "height": 1080})
        
        # Block known bot detection and tracking scripts to prevent "botDetected" errors
        # Using regex to ensure we match subdomains and paths correctly
        await page.route(re.compile(r".*pagesense\.io.*"), lambda route: route.abort())
        await page.route(re.compile(r".*google-analytics\.com.*"), lambda route: route.abort())
        await page.route(re.compile(r".*googletagmanager\.com.*"), lambda route: route.abort())
        await page.route(re.compile(r".*hotjar\.com.*"), lambda route: route.abort())
        
        await page.goto(url, wait_until="domcontentloaded", timeout=60000)
        await asyncio.sleep(2)  # –ñ–¥—ë–º –∑–∞–≥—Ä—É–∑–∫—É –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        
        try:
            await self._dismiss_popups(page)
            
            slug = url.rstrip("/").split("/")[-1]
            
            product_data = {
                "url": url,
                "slug": slug,
                "scraped_at": datetime.now().isoformat(),
            }
            
            # 1. –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            console.log("[cyan]Extracting header info...[/cyan]")
            header_info = await self._extract_header_info(page, slug)
            product_data.update(header_info)
            
            # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Å–ª–∞–π–¥–µ—Ä–∞
            console.log("[cyan]Extracting product images...[/cyan]")
            images = await self._extract_product_images(page)
            product_data["main_image"] = images.get("main_image")
            product_data["gallery"] = images.get("gallery", [])
            console.log(f"[green]Found {1 if images.get('main_image') else 0} main + {len(images.get('gallery', []))} gallery images[/green]")
            
            # 3. –°–∫—Ä–æ–ª–ª–∏–º –∫ —Ç–∞–±–∞–º
            await self._scroll_to_tabs(page)
            
            # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –í–°–ï —à–≤—ã (–ø—Ä–æ–∫—Ä—É—á–∏–≤–∞—è –∫–∞—Ä—É—Å–µ–ª—å)
            console.log("[cyan]Collecting all joints...[/cyan]")
            joints = await self._collect_all_tab_cards(page, "—à–≤—ã", "joints")
            product_data["joints"] = joints
            console.log(f"[green]Found {len(joints)} joints[/green]")
            
            # 4. –ò–∑–≤–ª–µ–∫–∞–µ–º –í–°–ï —Ñ–æ—Ä–º–∞—Ç—ã (–ø—Ä–æ–∫—Ä—É—á–∏–≤–∞—è –∫–∞—Ä—É—Å–µ–ª—å)
            console.log("[cyan]Collecting all formats...[/cyan]")
            formats = await self._collect_all_tab_cards(page, "—Ñ–æ—Ä–º–∞—Ç", "formats")
            product_data["available_formats"] = formats
            console.log(f"[green]Found {len(formats)} formats[/green]")
            
            # 5. –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª—ã (DOP, CE, –¢–µ–∫—Å—Ç—É—Ä—ã)
            console.log("[cyan]Collecting downloads...[/cyan]")
            downloads = await self._collect_downloads(page, slug)
            product_data["downloads"] = downloads
            console.log(f"[green]Downloaded {len(downloads)} files[/green]")
            
            # 6. Gemini –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
            if self.use_gemini and self.gemini:
                console.log("[cyan]Gemini enrichment...[/cyan]")
                product_data = await self._enrich_with_gemini(page, product_data, slug)
            
            return product_data
            
        finally:
            await page.close()
    
    async def _extract_header_info(self, page: Page, slug: str) -> dict:
        """–ò–∑–≤–ª–µ—á—å –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥—É–∫—Ç–µ –∏–∑ DOM"""
        
        info = {
            "name": slug.replace("-", " ").title(),
            "article": slug.upper().replace("-", ""),
            "texture": None,
            "color": None,
            "description": None,
        }
        
        # –ñ–¥—ë–º –Ω–µ–º–Ω–æ–≥–æ –ø–æ—Å–ª–µ –∑–∞–∫—Ä—ã—Ç–∏—è popup
        await asyncio.sleep(0.5)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º JavaScript –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
        try:
            result = await page.evaluate(r"""
                (() => {
                    const data = {};
                    
                    // –ù–∞–∑–≤–∞–Ω–∏–µ –∏ –∞—Ä—Ç–∏–∫—É–ª –∏–∑ h1
                    const h1 = document.querySelector('main h1, .c-product-hero h1, article h1');
                    if (h1) {
                        const text = h1.innerText.trim();
                        // –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –ø–µ—Ä–µ–Ω–æ—Å–∞–º —Å—Ç—Ä–æ–∫
                        const parts = text.split(/\n/).map(s => s.trim()).filter(s => s);
                        
                        // –ò—â–µ–º –∞—Ä—Ç–∏–∫—É–ª –≤ –ª—é–±–æ–π —á–∞—Å—Ç–∏ (—Ñ–æ—Ä–º–∞—Ç —Ç–∏–ø–∞ 0124A0)
                        for (const part of parts) {
                            const articleMatch = part.match(/^([0-9]{4}[A-Z0-9]{1,3})$/);
                            if (articleMatch) {
                                data.article = articleMatch[1];
                            } else if (!data.name) {
                                data.name = part;
                            }
                        }
                    }
                    
                    // –¢–µ–∫—Å—Ç—É—Ä–∞ –∏ –¶–≤–µ—Ç - –∏—â–µ–º –≤ —Å–ø–∏—Å–∫–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
                    const allDts = document.querySelectorAll('dt, .c-product-detail dt, .product-specs dt');
                    
                    const colorInfo = {
                        base_color: null,
                        additional_colors: [],
                        nuance: null
                    };

                    allDts.forEach(dt => {
                        const label = dt.innerText.trim().toLowerCase();
                        const dd = dt.nextElementSibling;
                        if (dd && dd.tagName === 'DD') {
                            const value = dd.innerText.trim();
                            if (label.includes('—Ç–µ–∫—Å—Ç—É—Ä')) {
                                data.texture = value;
                            } else if (label.includes('–Ω—é–∞–Ω—Å')) {
                                colorInfo.nuance = value;
                            } else if (label.includes('–±–∞–∑–æ–≤—ã–π —Ü–≤–µ—Ç')) {
                                colorInfo.base_color = value;
                            } else if (label.includes('–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ü–≤–µ—Ç–∞')) {
                                colorInfo.additional_colors.push(value);
                            } else if (label === '—Ü–≤–µ—Ç' || label === 'color') {
                                if (!colorInfo.base_color) colorInfo.base_color = value;
                            }
                        }
                    });
                    
                    // Fallback for color info from body text
                    if (!colorInfo.nuance && !colorInfo.base_color) {
                         const bodyText = document.body.innerText;
                         
                         const nuanceMatch = bodyText.match(/–ù—é–∞–Ω—Å[:\s]+([^\n]+)/i);
                         if (nuanceMatch) colorInfo.nuance = nuanceMatch[1].trim();
                         
                         const baseColorMatch = bodyText.match(/–ë–∞–∑–æ–≤—ã–π —Ü–≤–µ—Ç[:\s]+([^\n]+)/i);
                         if (baseColorMatch) colorInfo.base_color = baseColorMatch[1].trim();
                         
                         const addColorMatch = bodyText.match(/–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ü–≤–µ—Ç–∞[:\s]+([^\n]+)/i);
                         if (addColorMatch) {
                            colorInfo.additional_colors.push(addColorMatch[1].trim());
                         }
                    }

                    if (colorInfo.base_color || colorInfo.nuance || colorInfo.additional_colors.length > 0) {
                        data.color = colorInfo;
                    }
                    
                    // Fallback –¥–ª—è —Ç–µ–∫—Å—Ç—É—Ä—ã - –∏—â–µ–º —Å–ø—Ä–∞–≤–∞ –æ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞
                    if (!data.texture) {
                        const heroMeta = document.querySelector('.c-product-hero__meta, .product-meta');
                        if (heroMeta) {
                            const text = heroMeta.innerText;
                            if (text.includes('–¢–µ–∫—Å—Ç—É—Ä–∞')) {
                                const match = text.match(/–¢–µ–∫—Å—Ç—É—Ä–∞[:\s]*([^\n]+)/);
                                if (match) data.texture = match[1].trim();
                            }
                        }
                    }
                    
                    // –ï—â—ë –æ–¥–∏–Ω fallback - –∏—â–µ–º –ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                    if (!data.texture) {
                        const pageText = document.body.innerText;
                        const textureMatch = pageText.match(/–¢–µ–∫—Å—Ç—É—Ä–∞[:\s]*([–ê-–Ø–∞-—èA-Za-z\s]+?)(?:\n|–¶–≤–µ—Ç|–°—ã—Ä—å—ë|$)/);
                        if (textureMatch) {
                            data.texture = textureMatch[1].trim();
                        }
                    }
                    
                    // –û–ø–∏—Å–∞–Ω–∏–µ
                    const descSelectors = [
                        '.c-product-detail__description',
                        '.product-description',
                        '.c-product-hero__description',
                        'article .description',
                        '.c-text-block p'
                    ];
                    for (const sel of descSelectors) {
                        const el = document.querySelector(sel);
                        if (el && el.innerText.trim().length > 50) {
                            data.description = el.innerText.trim();
                            break;
                        }
                    }
                    
                    // –ï—Å–ª–∏ –Ω–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è, –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π –±–æ–ª—å—à–æ–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ
                    if (!data.description) {
                        const paragraphs = document.querySelectorAll('main p, article p');
                        for (const p of paragraphs) {
                            const text = p.innerText.trim();
                            if (text.length > 100 && !text.includes('cookie')) {
                                data.description = text;
                                break;
                            }
                        }
                    }
                    
                    return data;
                })()
            """)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º info –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –∏–∑ JavaScript
            if result.get("name"):
                info["name"] = result["name"]
            if result.get("article"):
                info["article"] = result["article"]
            if result.get("texture"):
                info["texture"] = result["texture"]
            if result.get("color"):
                info["color"] = result["color"]
            if result.get("description"):
                info["description"] = result["description"]
                
        except Exception as e:
            console.log(f"[yellow]Header extraction error: {e}[/yellow]")
        
        return info
    
    async def _extract_product_images(self, page: Page) -> Dict:
        """
        –ò–∑–≤–ª–µ—á—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Å–ª–∞–π–¥–µ—Ä–∞ –ø—Ä–æ–¥—É–∫—Ç–∞
        
        Returns:
            { "main_image": str, "gallery": [str, ...] }
        """
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º JavaScript –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ Slick —Å–ª–∞–π–¥–µ—Ä–∞
            result = await page.evaluate(r"""
                (() => {
                    // Find all main slide images (excluding clones for infinite scroll)
                    const mainSlides = document.querySelectorAll('.c-product-hero__image.slick-slide:not(.slick-cloned) img');
                    
                    const getCleanUrl = (img) => {
                        let src = img.src || img.dataset.src || '';
                        if (!src && img.srcset) {
                            // Take the largest one from srcset if available
                            const sources = img.srcset.split(',').map(s => s.trim().split(' ')[0]);
                            src = sources[sources.length - 1];
                        }
                        
                        if (src && src.includes('/styles/')) {
                            // Remove style part to get original high-res image
                            // Example: /sites/default/files/public/styles/product_carousel_655x420_/public/product-images/...
                            src = src.replace(/\/styles\/[^/]+\/public\//, '/');
                        }
                        return src;
                    };

                    const urls = Array.from(mainSlides).map(getCleanUrl).filter(url => url);
                    const uniqueUrls = Array.from(new Set(urls));

                    return {
                        main_image: uniqueUrls[0] || null,
                        gallery: uniqueUrls.slice(1),
                        count: uniqueUrls.length
                    };
                })()
            """)
            
            return result
            
        except Exception as e:
            console.log(f"[yellow]Image extraction error: {e}[/yellow]")
            return {"main_image": None, "gallery": []}
    
    async def _collect_all_tab_cards(self, page: Page, tab_text: str, card_type: str) -> List[Dict]:
        """
        –°–æ–±—Ä–∞—Ç—å –í–°–ï –∫–∞—Ä—Ç–æ—á–∫–∏ –∏–∑ —Ç–∞–±–∞, –ø—Ä–æ–∫—Ä—É—á–∏–≤–∞—è –∫–∞—Ä—É—Å–µ–ª—å –¥–æ –∫–æ–Ω—Ü–∞
        
        Args:
            page: Playwright —Å—Ç—Ä–∞–Ω–∏—Ü–∞
            tab_text: –¢–µ–∫—Å—Ç —Ç–∞–±–∞ –¥–ª—è –∫–ª–∏–∫–∞ ("—à–≤—ã" –∏–ª–∏ "—Ñ–æ—Ä–º–∞—Ç")
            card_type: –¢–∏–ø –∫–∞—Ä—Ç–æ—á–µ–∫ ("joints" –∏–ª–∏ "formats")
            
        Returns:
            –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞—Ä—Ç–æ—á–µ–∫
        """
        # –ö–ª–∏–∫–∞–µ–º –Ω–∞ —Ç–∞–±
        await self._click_tab(page, tab_text)
        await asyncio.sleep(0.8)
        
        all_cards = []
        seen_names = set()
        max_iterations = 20  # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
        iterations = 0
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º –∫–∞—Ä—É—Å–µ–ª—å –≤ –Ω–∞—á–∞–ª–æ
        for _ in range(10):
            if not await self._scroll_carousel(page, "prev"):
                break
            await asyncio.sleep(0.2)
        
        # –¢–µ–ø–µ—Ä—å –∏—Ç–µ—Ä–∏—Ä—É–µ–º –≤–ø–µ—Ä—ë–¥ –∏ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–∞—Ä—Ç–æ—á–∫–∏
        while iterations < max_iterations:
            iterations += 1
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—É—â–∏–µ –≤–∏–¥–∏–º—ã–µ –∫–∞—Ä—Ç–æ—á–∫–∏
            cards = await self._extract_visible_cards(page, card_type)
            
            new_cards_found = False
            for card in cards:
                name = card.get("name", "")
                if name and name not in seen_names:
                    seen_names.add(name)
                    all_cards.append(card)
                    new_cards_found = True
            
            # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º –∫ —Å–ª–µ–¥—É—é—â–∏–º –∫–∞—Ä—Ç–æ—á–∫–∞–º
            scrolled = await self._scroll_carousel(page, "next")
            if not scrolled:
                # –ö–∞—Ä—É—Å–µ–ª—å –∑–∞–∫–æ–Ω—á–∏–ª–∞—Å—å
                break
            
            await asyncio.sleep(0.3)
        
        return all_cards
    
    async def _extract_visible_cards(self, page: Page, card_type: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—É—â–∏—Ö –≤–∏–¥–∏–º—ã—Ö –∫–∞—Ä—Ç–æ—á–µ–∫"""
        
        cards = []
        card_elements = await page.query_selector_all(".c-shape-tile")
        
        for card_elem in card_elements:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∏–¥–∏–º–æ—Å—Ç—å –∫–∞—Ä—Ç–æ—á–∫–∏
                is_visible = await card_elem.is_visible()
                if not is_visible:
                    continue
                
                card_data = {}
                
                # –ù–∞–∑–≤–∞–Ω–∏–µ
                title_elem = await card_elem.query_selector(".c-shape-tile__title, p")
                if title_elem:
                    card_data["name"] = clean_text(await title_elem.inner_text()) or ""
                else:
                    # –ë–µ—Ä—ë–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞—Ä—Ç–æ—á–∫–∏
                    full_text = await card_elem.inner_text()
                    # –î–ª—è —à–≤–æ–≤ ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ
                    if card_type == "joints" and len(full_text) < 50:
                        card_data["name"] = clean_text(full_text) or ""
                
                if not card_data.get("name"):
                    continue
                
                # –î–ª—è —Ñ–æ—Ä–º–∞—Ç–æ–≤ ‚Äî –∏–∑–≤–ª–µ–∫–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
                if card_type == "formats":
                    dl_elem = await card_elem.query_selector("dl.c-shape-tile__list, dl")
                    if dl_elem:
                        dt_elements = await dl_elem.query_selector_all("dt")
                        dd_elements = await dl_elem.query_selector_all("dd")
                        
                        for dt, dd in zip(dt_elements, dd_elements):
                            label = clean_text(await dt.inner_text()) or ""
                            value = clean_text(await dd.inner_text()) or ""
                            label_lower = label.lower()
                            
                            if "—Ä–∞–∑–º–µ—Ä" in label_lower:
                                card_data["dimensions"] = value
                            elif "–Ω–∞–ª–∏—á–∏–∏" in label_lower or "–ø–µ—Ä—Ñ–æ—Ä–∞" in label_lower:
                                card_data["availability"] = value
                            elif "m¬≤" in label_lower or "–º¬≤" in label_lower or "number" in label_lower:
                                card_data["pieces_per_m2"] = extract_number(value)
                            elif "–ø–∞–ª–µ—Ç" in label_lower:
                                card_data["pieces_per_pallet"] = extract_number(value)
                            elif "–≤–µ—Å" in label_lower:
                                card_data["weight_kg"] = extract_weight(value)
                    
                    # –ï—Å–ª–∏ –Ω–µ—Ç dl ‚Äî —ç—Ç–æ –Ω–µ —Ñ–æ—Ä–º–∞—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    if not dl_elem and card_type == "formats":
                        continue
                
                # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                img_elem = await card_elem.query_selector("img")
                if img_elem:
                    card_data["image_url"] = await img_elem.get_attribute("src")
                
                cards.append(card_data)
                
            except Exception as e:
                console.log(f"[yellow]Card extraction error: {e}[/yellow]")
                continue
        
        return cards
    
    async def _scroll_carousel(self, page: Page, direction: str = "next") -> bool:
        """
        –ü—Ä–æ–∫—Ä—É—Ç–∏—Ç—å –∫–∞—Ä—É—Å–µ–ª—å –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏
        
        Returns:
            True –µ—Å–ª–∏ –ø—Ä–æ–∫—Ä—É—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞, False –µ—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –∫—Ä–∞–π
        """
        try:
            # –ò—â–µ–º —Å—Ç—Ä–µ–ª–∫–∏ –∫–∞—Ä—É—Å–µ–ª–∏
            if direction == "next":
                selectors = [
                    ".c-carousel__arrow--next:not([disabled])",
                    ".slick-next:not(.slick-disabled)",
                    ".carousel-next:not(:disabled)",
                    "button[aria-label='Next']:not([disabled])",
                ]
            else:
                selectors = [
                    ".c-carousel__arrow--prev:not([disabled])",
                    ".slick-prev:not(.slick-disabled)",
                    ".carousel-prev:not(:disabled)",
                    "button[aria-label='Previous']:not([disabled])",
                ]
            
            for selector in selectors:
                arrow = await page.query_selector(selector)
                if arrow:
                    is_visible = await arrow.is_visible()
                    if is_visible:
                        await arrow.click()
                        return True
            
            return False
            
        except Exception:
            return False
    
    async def _click_tab(self, page: Page, tab_text: str) -> bool:
        """–ö–ª–∏–∫–Ω—É—Ç—å –Ω–∞ —Ç–∞–± –ø–æ —Ç–µ–∫—Å—Ç—É"""
        try:
            tabs = await page.query_selector_all("a.c-tabs__link, .c-tabs__item, button.c-tabs__link")
            for tab in tabs:
                text = await tab.inner_text()
                if tab_text.lower() in text.lower():
                    await tab.click()
                    return True
        except Exception as e:
            console.log(f"[yellow]Tab click failed: {e}[/yellow]")
        return False
    
    async def _scroll_to_tabs(self, page: Page):
        """–°–∫—Ä–æ–ª–ª–∏—Ç—å –∫ —Å–µ–∫—Ü–∏–∏ —Ç–∞–±–æ–≤"""
        try:
            tabs_section = await page.query_selector(".c-tabs")
            if tabs_section:
                await tabs_section.scroll_into_view_if_needed()
                await asyncio.sleep(0.5)
            else:
                await page.evaluate("window.scrollBy(0, 800)")
                await asyncio.sleep(0.5)
        except Exception:
            await page.evaluate("window.scrollBy(0, 800)")
    
    async def _dismiss_popups(self, page: Page):
        """–ó–∞–∫—Ä—ã—Ç—å popup-—ã"""
        try:
            close_btn = await page.query_selector(".popup__close")
            if close_btn:
                is_visible = await close_btn.is_visible()
                if is_visible:
                    console.log("[yellow]Closing popup[/yellow]")
                    await close_btn.click()
                    await asyncio.sleep(0.5)
            
            cookie_btn = await page.query_selector("#onetrust-accept-btn-handler")
            if cookie_btn:
                is_visible = await cookie_btn.is_visible()
                if is_visible:
                    await cookie_btn.click()
                    await asyncio.sleep(0.3)
            
            await page.evaluate("""
                document.querySelectorAll('.popup__overlay, .popup').forEach(el => {
                    el.style.display = 'none';
                });
            """)
        except Exception:
            pass
    
    async def _collect_downloads(self, page: Page, slug: str) -> List[Dict]:
        """
        –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª—ã –∏–∑ —Å–µ–∫—Ü–∏–∏ '–ó–∞–≥—Ä—É–∑–∫–∏ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è'
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
        """
        import httpx
        
        downloads = []
        product_dir = DOWNLOADS_DIR / slug
        product_dir.mkdir(parents=True, exist_ok=True)
        
        # –°–∫—Ä–æ–ª–ª–∏–º –∫ —Å–µ–∫—Ü–∏–∏ –∑–∞–≥—Ä—É–∑–æ–∫
        await page.evaluate("window.scrollBy(0, 1500)")
        await asyncio.sleep(0.5)
        
        # –ò—â–µ–º —Å–µ–∫—Ü–∏—é –∑–∞–≥—Ä—É–∑–æ–∫
        downloads_section = await page.query_selector(".c-downloads, .downloads-section")
        if downloads_section:
            await downloads_section.scroll_into_view_if_needed()
            await asyncio.sleep(0.5)
        
        # 1. –°–∫–∞—á–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—É—Ä—ã (–ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏)
        try:
            textures_downloaded = await self._download_textures(page, product_dir, slug)
            downloads.extend(textures_downloaded)
        except Exception as e:
            console.log(f"[yellow]Textures download failed: {e}[/yellow]")
        
        # 2. –°–∫–∞—á–∏–≤–∞–µ–º DOP PDF
        try:
            dop_file = await self._download_form_pdf(page, product_dir, slug, "dop")
            if dop_file:
                downloads.append(dop_file)
        except Exception as e:
            console.log(f"[yellow]DOP download failed: {e}[/yellow]")
        
        # 3. –°–∫–∞—á–∏–≤–∞–µ–º CE PDF
        try:
            ce_file = await self._download_form_pdf(page, product_dir, slug, "ce")
            if ce_file:
                downloads.append(ce_file)
        except Exception as e:
            console.log(f"[yellow]CE download failed: {e}[/yellow]")
        
        return downloads
    
    async def _download_textures(self, page: Page, product_dir: Path, slug: str) -> List[Dict]:
        """–°–∫–∞—á–∞—Ç—å —Ç–µ–∫—Å—Ç—É—Ä—ã (–ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ ZIP)"""
        import httpx
        
        textures = []
        
        # –ö–ª–∏–∫–∞–µ–º –Ω–∞ —Ç–∞–± "–¢–µ–∫—Å—Ç—É—Ä—ã" —á—Ç–æ–±—ã –æ—Ç–∫—Ä—ã—Ç—å
        labels = await page.query_selector_all(".c-downloads__label, label.c-downloads__label")
        for label in labels:
            text = await label.inner_text()
            if "—Ç–µ–∫—Å—Ç—É—Ä" in text.lower():
                await label.click()
                await asyncio.sleep(0.5)
                break
        
        # –ò—â–µ–º –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
        download_links = await page.query_selector_all("a.c-btn__download, a.c-brochure-tile__button, a[href*='textures'], a[href$='.zip']")
        
        for link in download_links:
            try:
                href = await link.get_attribute("href")
                if not href:
                    continue
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π URL
                if href.startswith("/"):
                    href = f"{self.base_url}{href}"
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞
                filename = href.split("/")[-1]
                if not filename:
                    filename = f"{slug}_textures.zip"
                
                local_path = product_dir / filename
                
                # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
                console.log(f"[cyan]Downloading texture: {filename}[/cyan]")
                async with httpx.AsyncClient(follow_redirects=True) as client:
                    response = await client.get(href)
                    if response.status_code == 200:
                        with open(local_path, "wb") as f:
                            f.write(response.content)
                        
                        textures.append({
                            "type": "textures",
                            "filename": filename,
                            "local_path": str(local_path),
                            "original_url": href,
                            "size_bytes": len(response.content),
                        })
                        console.log(f"[green]‚úì Saved: {filename}[/green]")
            except Exception as e:
                console.log(f"[yellow]Texture download error: {e}[/yellow]")
        
        return textures
    
    async def _download_form_pdf(self, page: Page, product_dir: Path, slug: str, doc_type: str) -> Optional[Dict]:
        """
        –°–∫–∞—á–∞—Ç—å PDF —á–µ—Ä–µ–∑ —Ñ–æ—Ä–º—É (DOP –∏–ª–∏ CE)
        
        Args:
            page: –°—Ç—Ä–∞–Ω–∏—Ü–∞ Playwright
            product_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            slug: Slug –ø—Ä–æ–¥—É–∫—Ç–∞
            doc_type: 'dop' –∏–ª–∏ 'ce'
        """
        import httpx
        
        # –ö–ª–∏–∫–∞–µ–º –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç–∞–±
        label_selector = f".js--ajax-form-trigger--{doc_type}"
        label = await page.query_selector(label_selector)
        if not label:
            # –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ —Ç–µ–∫—Å—Ç
            labels = await page.query_selector_all(".c-downloads__label")
            for lbl in labels:
                text = await lbl.inner_text()
                if doc_type.upper() in text:
                    label = lbl
                    break
        
        if not label:
            return None
        
        await label.click()
        await asyncio.sleep(0.8)
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã
        form_selector = f"form[id*='{doc_type}-download-form']"
        form = await page.query_selector(form_selector)
        if not form:
            return None
        
        form_action = await form.get_attribute("action")
        if not form_action:
            return None
        
        if form_action.startswith("/"):
            form_action = f"{self.base_url}{form_action}"
        
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã
        form_data = {}
        inputs = await form.query_selector_all("input, select")
        for inp in inputs:
            name = await inp.get_attribute("name")
            value = await inp.get_attribute("value")
            if name:
                # –î–ª—è select –ø–æ–ª—É—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                tag = await inp.evaluate("el => el.tagName.toLowerCase()")
                if tag == "select":
                    selected = await inp.query_selector("option:checked")
                    if selected:
                        value = await selected.get_attribute("value")
                form_data[name] = value or ""
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ä–º—É
        console.log(f"[cyan]Downloading {doc_type.upper()} PDF...[/cyan]")
        
        try:
            async with httpx.AsyncClient(follow_redirects=True, timeout=30) as client:
                response = await client.post(
                    form_action,
                    data=form_data,
                    headers={
                        "Content-Type": "application/x-www-form-urlencoded",
                        "Accept": "application/pdf,*/*",
                    }
                )
                
                if response.status_code == 200 and len(response.content) > 1000:
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞
                    filename = f"{slug}_{doc_type}.pdf"
                    content_disp = response.headers.get("content-disposition", "")
                    if "filename=" in content_disp:
                        import re
                        match = re.search(r'filename="?([^";]+)"?', content_disp)
                        if match:
                            filename = match.group(1)
                    
                    local_path = product_dir / filename
                    
                    with open(local_path, "wb") as f:
                        f.write(response.content)
                    
                    console.log(f"[green]‚úì Saved: {filename}[/green]")
                    
                    return {
                        "type": doc_type,
                        "filename": filename,
                        "local_path": str(local_path),
                        "original_url": form_action,
                        "size_bytes": len(response.content),
                    }
        except Exception as e:
            console.log(f"[yellow]{doc_type.upper()} form submission failed: {e}[/yellow]")
        
        return None
    
    async def _enrich_with_gemini(self, page: Page, product_data: dict, slug: str) -> dict:
        """–û–±–æ–≥–∞—Ç–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é Gemini (—Å–∫—Ä–∏–Ω—à–æ—Ç + –∞–Ω–∞–ª–∏–∑)"""
        
        if not self.gemini:
            return product_data
        
        try:
            # –°–∫—Ä–∏–Ω—à–æ—Ç –¥–ª—è Gemini
            screenshot_path = SCREENSHOTS_DIR / f"{slug}_full.png"
            await page.screenshot(path=str(screenshot_path), full_page=False)
            
            # –ê–Ω–∞–ª–∏–∑ –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ—ã –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö
            if not product_data.get("texture") or not product_data.get("color"):
                header_info = self.gemini.analyze_product_info(screenshot_path)
                
                if not product_data.get("texture"):
                    product_data["texture"] = header_info.get("texture")
                if not product_data.get("color"):
                    product_data["color"] = header_info.get("color")
                if not product_data.get("raw_material"):
                    product_data["raw_material"] = header_info.get("raw_material")
                if not product_data.get("description"):
                    product_data["description"] = header_info.get("description")
        except Exception as e:
            console.log(f"[yellow]Gemini enrichment failed: {e}[/yellow]")
        
        return product_data


async def robust_scrape(url: str, api_key: str = None, headless: bool = True) -> dict:
    """–£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è robust —Å–∫—Ä–∞–ø–ø–∏–Ω–≥–∞"""
    async with RobustProductScraper(api_key=api_key, headless=headless) as scraper:
        return await scraper.scrape_product(url)
